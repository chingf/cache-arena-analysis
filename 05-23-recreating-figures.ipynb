{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from scipy.io import loadmat\n",
    "from scipy import optimize\n",
    "from math import pi, log2\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files = [m for m in os.listdir(\"data\") if m.endswith('mat')]\n",
    "session_list = pd.read_excel('data/CacheRetrieveSessionList.xlsx', index_col=0)\n",
    "fps = 20\n",
    "cmap = cm.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def estimate_center(x, y):\n",
    "    method_2 = \"leastsq\"\n",
    "\n",
    "    def calc_R(xc, yc):\n",
    "        \"\"\" calculate the distance of each 2D points from the center (xc, yc) \"\"\"\n",
    "        return np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "\n",
    "    def f_2(c):\n",
    "        \"\"\" calculate the algebraic distance between the data points and the mean circle centered at c=(xc, yc) \"\"\"\n",
    "        Ri = calc_R(*c)\n",
    "        return Ri - Ri.mean()\n",
    "\n",
    "    center_estimate = np.mean(x), np.mean(y)\n",
    "    center_2, ier = optimize.leastsq(f_2, center_estimate)\n",
    "    return center_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_xy(f, in_bound=True):\n",
    "    x = np.squeeze(np.array(f['X']))\n",
    "    y = np.squeeze(np.array(f['Y']))\n",
    "    x_c, y_c = estimate_center(x, y)\n",
    "    x -= x_c; y -= y_c\n",
    "    length = np.sqrt(np.square(x) + np.square(y))\n",
    "    frames = np.arange(x.size)\n",
    "    if in_bound:\n",
    "        oob = np.logical_or(length <= 145, length >= 215)\n",
    "        x = x[np.logical_not(oob)]\n",
    "        y = y[np.logical_not(oob)]\n",
    "        frames = frames[np.logical_not(oob)]\n",
    "    return x, y, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_theta(f):\n",
    "    x, y, frames = get_xy(f, in_bound=True)\n",
    "    theta = np.arctan2(y, x)\n",
    "    theta = np.mod(theta, 2*pi)\n",
    "    boundaries = np.linspace(0, 2*pi, 16, endpoint=False)\n",
    "    boundaries = np.append(boundaries, [2*pi])\n",
    "    theta = np.digitize(theta, boundaries)\n",
    "    return theta, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_velocity(f):\n",
    "    x, y, frames = get_xy(f, in_bound=False)\n",
    "    delta_x = x[1:] - x[:-1]\n",
    "    delta_y = y[1:] - y[:-1]\n",
    "    frames = frames[1:]\n",
    "    velocity = np.sqrt(np.square(delta_x) + np.square(delta_y)) # pixels/frame\n",
    "    velocity = velocity*fps # pixels/s\n",
    "    smoothing_kernel = np.ones(fps)/fps\n",
    "    velocity = np.convolve(velocity, smoothing_kernel, \"valid\")\n",
    "    frames = frames[:velocity.size]\n",
    "    return velocity, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wedges(f):\n",
    "    x, y, frames = get_xy(f, in_bound=True)\n",
    "    theta = np.mod(np.arctan2(y, x), 2*pi)\n",
    "    boundaries = np.linspace(0, 2*pi, 16, endpoint=False)\n",
    "    boundaries = np.append(boundaries, [2*pi])\n",
    "    wedges = np.digitize(theta, boundaries)\n",
    "    wedges = np.mod(16-wedges, 16) + 1\n",
    "    return wedges, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fr(spikes):\n",
    "    smoothing_kernel = np.ones(fps+1)/(fps+1) # One sec smoothing\n",
    "    fr = np.convolve(spikes, smoothing_kernel, \"valid\")\n",
    "    fr_frames = np.arange(spikes.size)[\n",
    "        smoothing_kernel.size//2:-smoothing_kernel.size//2+1\n",
    "        ]\n",
    "    return fr, fr_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutual_info(contexts, fr):\n",
    "    mean_fr = np.mean(fr)\n",
    "    mutual_info = 0\n",
    "    for ctxt in np.unique(contexts):\n",
    "        prob = np.sum(contexts==ctxt)/contexts.size\n",
    "        ctxt_mean_fr = np.mean(fr[contexts==ctxt])\n",
    "        try:\n",
    "            log_term = log2(ctxt_mean_fr/mean_fr)\n",
    "        except:\n",
    "            log_term = 0\n",
    "        mutual_info += prob*ctxt_mean_fr*log_term\n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shuffle(spikes):\n",
    "    spikes = spikes.copy()\n",
    "    shift = np.random.choice(np.arange(1, spikes.size))\n",
    "    return np.roll(spikes, shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying place cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_mod = 0\n",
    "not_place_mod = 0\n",
    "spatial_infos = []\n",
    "results = {}\n",
    "for mat_file in mat_files:\n",
    "    # Load data\n",
    "    results[mat_file] = []\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), theta_frames)]\n",
    "    spikes = np.array(f['S'])\n",
    "    \n",
    "    for neur in np.arange(spikes.shape[1]):\n",
    "        neur_spikes = spikes[:, neur]\n",
    "        neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "        valid_frames = np.intersect1d(fr_frames, wedge_frames)\n",
    "        spatial_info = get_mutual_info(\n",
    "            wedges[np.isin(wedge_frames, valid_frames)],\n",
    "            neur_fr[np.isin(fr_frames, valid_frames)]\n",
    "            )\n",
    "        shuffled_info = []\n",
    "        shuffled_peak_fr = []\n",
    "        for _ in range(110):\n",
    "            shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "            shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "            shuffled_info.append(get_mutual_info(\n",
    "                wedges[np.isin(wedge_frames, valid_frames)],\n",
    "                shuffled_fr[np.isin(fr_frames, valid_frames)]\n",
    "                ))\n",
    "            shuffled_peak_fr.append(shuffled_fr.max())\n",
    "        shuffled_info = np.array(shuffled_info)\n",
    "        high_mutual_info = np.sum(shuffled_info < spatial_info) > 0.99*shuffled_info.size\n",
    "        df = pd.DataFrame({\n",
    "            \"loc\":wedges[np.isin(wedge_frames, valid_frames)],\n",
    "            \"spikerate\":neur_fr[np.isin(fr_frames, valid_frames)]\n",
    "            })\n",
    "        spatial_infos.append(spatial_info)\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.pointplot(x=\"loc\", y=\"spikerate\", data=df)\n",
    "        if high_mutual_info:\n",
    "            place_mod += 1\n",
    "            plt.title(\"Place Cell\")\n",
    "            results.append(neur)\n",
    "        else:\n",
    "            not_place_mod += 1\n",
    "            plt.title(\"Not Place Cell\")\n",
    "        plt.show()\n",
    "        print(spatial_info)\n",
    "with open(\"spatial.p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying specific episode cells\n",
    "Looking at a window around each cache. Specificity for a cache at a specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_frames(\n",
    "    cache_site, cache_sites,\n",
    "    cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_pokes = cache_frames_poke[event_idxs]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_pokes = [cache_pokes]\n",
    "    window = 30\n",
    "    try:\n",
    "        frames = [np.arange(c-window, c+window+1) for c in cache_pokes]\n",
    "    except:\n",
    "        print(cache_frames_poke)\n",
    "        print(cache_site)\n",
    "        print(cache_sites)\n",
    "        print(cache_pokes)\n",
    "        print(type(cache_pokes))\n",
    "        import pdb; pdb.set_trace()\n",
    "    frames = np.concatenate(frames)\n",
    "    return frames.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noncache_frames(\n",
    "    wedges, wedge_frames, cache_site,\n",
    "    cache_frames, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "    cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_frames_enter = [cache_frames_enter]\n",
    "        cache_frames_exit = [cache_frames_exit]\n",
    "    event_frames = [\n",
    "        np.arange(c, cache_frames_exit[i]) for i, c in enumerate(cache_frames_enter)\n",
    "        ]\n",
    "    event_frames = np.concatenate(event_frames)\n",
    "    noncache = np.logical_not(np.isin(wedge_frames, cache_frames))\n",
    "    nonevent = np.logical_not(np.isin(wedge_frames, event_frames))\n",
    "    frames = wedge_frames[np.logical_and(noncache, nonevent)]\n",
    "    return frames.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-10-15424b41b647>(11)get_mutual_info()\n",
      "-> log_term = 0\n",
      "(Pdb) l\n",
      "  6  \t        ctxt_mean_fr = np.mean(fr[contexts==ctxt])\n",
      "  7  \t        try:\n",
      "  8  \t            log_term = log2(ctxt_mean_fr/mean_fr)\n",
      "  9  \t        except:\n",
      " 10  \t            import pdb; pdb.set_trace()\n",
      " 11  ->\t            log_term = 0\n",
      " 12  \t        mutual_info += prob*ctxt_mean_fr*log_term\n",
      " 13  \t    return mutual_info\n",
      "[EOF]\n",
      "(Pdb) log_term\n",
      "0.062181576014567065\n",
      "(Pdb) ctxt_mean_fr\n",
      "0.0\n",
      "(Pdb) mean_fr\n",
      "0.05939741635105467\n",
      "(Pdb) log2(ctxt_mean_fr/mean_fr)\n",
      "*** ValueError: math domain error\n",
      "(Pdb) c\n",
      "> <ipython-input-10-15424b41b647>(11)get_mutual_info()\n",
      "-> log_term = 0\n",
      "(Pdb) ctxt_mean_fr\n",
      "0.0\n",
      "(Pdb) mean_fr\n",
      "0.06931538548094138\n",
      "(Pdb) c\n",
      "> <ipython-input-10-15424b41b647>(11)get_mutual_info()\n",
      "-> log_term = 0\n",
      "(Pdb) ctxt_mean_fr\n",
      "0.0\n",
      "(Pdb) mean_fr\n",
      "0.10268099996138955\n",
      "(Pdb) np.sum(contexts==ctxt)\n",
      "122\n",
      "(Pdb) ncf.size\n",
      "2770\n",
      "(Pdb) exit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-15424b41b647>\u001b[0m in \u001b[0;36mget_mutual_info\u001b[0;34m(contexts, fr)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mlog_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctxt_mean_fr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmean_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2d6a7238d159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mshuffled_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_spikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 shuffled_info.append(get_mutual_info(\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_fr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     ))\n\u001b[1;32m     47\u001b[0m                 \u001b[0mshuffled_peak_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-15424b41b647>\u001b[0m in \u001b[0;36mget_mutual_info\u001b[0;34m(contexts, fr)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mlog_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmutual_info\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mctxt_mean_fr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmutual_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-15424b41b647>\u001b[0m in \u001b[0;36mget_mutual_info\u001b[0;34m(contexts, fr)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mlog_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmutual_info\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mctxt_mean_fr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlog_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmutual_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cache_mod = 0\n",
    "not_cache_mod = 0\n",
    "cache_infos = []\n",
    "results = {}\n",
    "for mat_file in mat_files:\n",
    "    # Load data\n",
    "    results[mat_file] = {}\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "    cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "    cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "    cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "    was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "    was_cache = np.logical_not(was_retrieval)\n",
    "    spikes = np.array(f['S'])\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        results[mat_file][cache_site] = []\n",
    "        cache_frames = get_cache_frames(\n",
    "            cache_site, cache_sites,\n",
    "            cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "            )\n",
    "        noncache_frames = get_noncache_frames(\n",
    "            wedges, wedge_frames, cache_site,\n",
    "            cache_frames, cache_frames_enter, cache_frames_exit\n",
    "            )    \n",
    "        for neur in np.arange(spikes.shape[1]):\n",
    "            neur_spikes = spikes[:, neur]\n",
    "            neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "            cf = np.intersect1d(fr_frames, cache_frames)\n",
    "            ncf = np.intersect1d(fr_frames, noncache_frames)\n",
    "            combined_frames = np.concatenate([cf, ncf])\n",
    "            contexts = np.concatenate([np.ones(cf.size), np.zeros(ncf.size)])\n",
    "            cache_info = get_mutual_info(\n",
    "                contexts, neur_fr[np.isin(fr_frames, combined_frames)]\n",
    "                )\n",
    "            shuffled_info = []\n",
    "            shuffled_peak_fr = []\n",
    "            for _ in range(110):\n",
    "                shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "                shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "                shuffled_info.append(get_mutual_info(\n",
    "                    contexts, shuffled_fr[np.isin(fr_frames, combined_frames)]\n",
    "                    ))\n",
    "                shuffled_peak_fr.append(shuffled_fr.max())\n",
    "            shuffled_info = np.array(shuffled_info)\n",
    "            high_mutual_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "            cache_infos.append(cache_info)\n",
    "            if high_mutual_info:\n",
    "                cache_mod += 1\n",
    "                results[mat_file][cache_site].append(neur)\n",
    "            else:\n",
    "                not_cache_mod += 1\n",
    "with open(\"specific_cache.p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying general episode cells\n",
    "Looking at a window around each cache. Specificity for any cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cache_frames(\n",
    "    wedges, wedge_frames, cache_sites,\n",
    "    cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    cache_frames = []\n",
    "    cache_related_frames = []\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "        _cache_pokes = cache_frames_poke[event_idxs]\n",
    "        _cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "        _cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "        if event_idxs.size == 1:\n",
    "            _cache_pokes = [_cache_pokes]\n",
    "            _cache_frames_enter = [_cache_frames_enter]\n",
    "            _cache_frames_exit = [_cache_frames_exit]\n",
    "        window = 20\n",
    "        _cache_frames = [np.arange(c-window, c+window+1) for c in _cache_pokes]\n",
    "        _cache_frames = np.concatenate(_cache_frames)\n",
    "        cache_frames.append(_cache_frames)\n",
    "        visit_frames = [\n",
    "            np.arange(c, _cache_frames_exit[i]) for i, c in enumerate(_cache_frames_enter)\n",
    "            ]\n",
    "        visit_frames = np.concatenate(visit_frames)\n",
    "        cache_related_frames.append(_cache_frames)\n",
    "        cache_related_frames.append(visit_frames)\n",
    "    cache_frames = np.concatenate(cache_frames)\n",
    "    cache_related_frames = np.concatenate(cache_related_frames)\n",
    "    \n",
    "    noncache_frames = []\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "        _cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "        _cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "        _wedge_frames = wedge_frames[wedges == cache_site]\n",
    "        if event_idxs.size == 1:\n",
    "            _cache_frames_enter = [_cache_frames_enter]\n",
    "            _cache_frames_exit = [_cache_frames_exit]\n",
    "        noncache = np.logical_not(np.isin(_wedge_frames, cache_frames))\n",
    "        nonevent = np.logical_not(np.isin(_wedge_frames, cache_related_frames))\n",
    "        _noncache_frames = _wedge_frames[np.logical_and(noncache, nonevent)]\n",
    "        noncache_frames.append(_noncache_frames)\n",
    "    noncache_frames = np.concatenate(noncache_frames)\n",
    "    \n",
    "    return cache_frames.astype(int), noncache_frames.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_mod = 0\n",
    "not_cache_mod = 0\n",
    "cache_infos = []\n",
    "results = {}\n",
    "for mat_file in mat_files:\n",
    "    # Load data\n",
    "    results[mat_file] = []\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "    cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "    cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "    cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "    was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "    was_cache = np.logical_not(was_retrieval)\n",
    "    spikes = np.array(f['S'])\n",
    "    cache_frames, noncache_frames = get_all_cache_frames(\n",
    "        wedges, wedge_frames, cache_sites,\n",
    "        cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "        )\n",
    "    for neur in np.arange(spikes.shape[1]):\n",
    "        neur_spikes = spikes[:, neur]\n",
    "        neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "        cf = np.intersect1d(fr_frames, cache_frames)\n",
    "        ncf = np.intersect1d(fr_frames, noncache_frames)\n",
    "        combined_frames = np.concatenate([cf, ncf])\n",
    "        contexts = np.concatenate([np.ones(cf.size), np.zeros(ncf.size)])\n",
    "        cache_info = get_mutual_info(\n",
    "            contexts, neur_fr[np.isin(fr_frames, combined_frames)]\n",
    "            )\n",
    "        shuffled_info = []\n",
    "        shuffled_peak_fr = []\n",
    "        for _ in range(110):\n",
    "            shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "            shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "            shuffled_info.append(get_mutual_info(\n",
    "                contexts, shuffled_fr[np.isin(fr_frames, combined_frames)]\n",
    "                ))\n",
    "            shuffled_peak_fr.append(shuffled_fr.max())\n",
    "        shuffled_info = np.array(shuffled_info)\n",
    "        high_mutual_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "        cache_infos.append(cache_info)\n",
    "        if high_mutual_info:\n",
    "            cache_mod += 1\n",
    "            results[mat_file].append(neur)\n",
    "        else:\n",
    "            not_cache_mod += 1\n",
    "with open(\"general_cache.p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"specific_cache.p\", \"rb\") as f:\n",
    "    specific_cache_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_cache_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control: Identifying specific episode cells\n",
    "Looking at a window around each cache. Specificity for a cache at a specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chingf/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/chingf/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:94: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-e897cb479c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mshuffled_spikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcircular_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneur_spikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mshuffled_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_spikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 shuffled_info.append(get_mutual_info(\n\u001b[1;32m     90\u001b[0m                     \u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_fr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-cbeff930735a>\u001b[0m in \u001b[0;36mget_fr\u001b[0;34m(spikes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msmoothing_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# One sec smoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspikes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     fr_frames = np.arange(spikes.size)[\n\u001b[1;32m      5\u001b[0m         \u001b[0msmoothing_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msmoothing_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_cache_frames(\n",
    "    cache_site, cache_sites,\n",
    "    cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_pokes = cache_frames_poke[event_idxs]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_pokes = [cache_pokes]\n",
    "    window = 30\n",
    "    try:\n",
    "        frames = [np.arange(c-window, c+window+1) for c in cache_pokes]\n",
    "    except:\n",
    "        print(cache_frames_poke)\n",
    "        print(cache_site)\n",
    "        print(cache_sites)\n",
    "        print(cache_pokes)\n",
    "        print(type(cache_pokes))\n",
    "        import pdb; pdb.set_trace()\n",
    "    frames = np.concatenate(frames)\n",
    "    return frames.astype(int)\n",
    "\n",
    "def get_noncache_frames(\n",
    "    wedges, wedge_frames, cache_site,\n",
    "    cache_frames, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "    cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_frames_enter = [cache_frames_enter]\n",
    "        cache_frames_exit = [cache_frames_exit]\n",
    "    event_frames = [\n",
    "        np.arange(c, cache_frames_exit[i]) for i, c in enumerate(cache_frames_enter)\n",
    "        ]\n",
    "    event_frames = np.concatenate(event_frames)\n",
    "    noncache = np.logical_not(np.isin(wedge_frames, cache_frames))\n",
    "    nonevent = np.logical_not(np.isin(wedge_frames, event_frames))\n",
    "    frames = wedge_frames[np.logical_and(noncache, nonevent)]\n",
    "    return frames.astype(int)\n",
    "\n",
    "cache_mod = 0\n",
    "not_cache_mod = 0\n",
    "cache_infos = []\n",
    "results = {}\n",
    "for mat_file in mat_files:\n",
    "    # Load data\n",
    "    results[mat_file] = {}\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "    cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "    cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "    cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "    was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "    was_cache = np.logical_not(was_retrieval)\n",
    "    spikes = np.array(f['S'])\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        results[mat_file][cache_site] = []\n",
    "        cache_frames = get_cache_frames(\n",
    "            cache_site, cache_sites,\n",
    "            cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "            )\n",
    "        noncache_frames = get_noncache_frames(\n",
    "            wedges, wedge_frames, cache_site,\n",
    "            cache_frames, cache_frames_enter, cache_frames_exit\n",
    "            )    \n",
    "        for neur in np.arange(spikes.shape[1]):\n",
    "            neur_spikes = spikes[:, neur]\n",
    "            neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "            cf = np.intersect1d(fr_frames, cache_frames)\n",
    "            ncf = np.intersect1d(fr_frames, noncache_frames)\n",
    "            combined_frames = np.concatenate([cf, ncf])\n",
    "            contexts = np.concatenate([np.ones(cf.size), np.zeros(ncf.size)])\n",
    "            for _ in range(3):\n",
    "                np.random.shuffle(contexts)\n",
    "            cache_info = get_mutual_info(\n",
    "                contexts, neur_fr[np.isin(fr_frames, combined_frames)]\n",
    "                )\n",
    "            shuffled_info = []\n",
    "            shuffled_peak_fr = []\n",
    "            for _ in range(110):\n",
    "                shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "                shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "                shuffled_info.append(get_mutual_info(\n",
    "                    contexts, shuffled_fr[np.isin(fr_frames, combined_frames)]\n",
    "                    ))\n",
    "                shuffled_peak_fr.append(shuffled_fr.max())\n",
    "            shuffled_info = np.array(shuffled_info)\n",
    "            high_mutual_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "            cache_infos.append(cache_info)\n",
    "            if high_mutual_info:\n",
    "                cache_mod += 1\n",
    "                results[mat_file][cache_site].append(neur)\n",
    "            else:\n",
    "                not_cache_mod += 1\n",
    "with open(\"specific_cache_shuffled.p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying specific episode cells by visit\n",
    "Looking at the entire cache/retrieval visit. Specificity for a cache at a specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visit_frames(\n",
    "    wedges, wedge_frames, cache_site,\n",
    "    cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "    cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_frames_enter = [cache_frames_enter]\n",
    "        cache_frames_exit = [cache_frames_exit]\n",
    "    visit_frames = [\n",
    "        np.arange(c, cache_frames_exit[i]) for i, c in enumerate(cache_frames_enter)\n",
    "        ]\n",
    "    visit_frames = np.concatenate(visit_frames)\n",
    "    nonvisit = np.logical_not(np.isin(wedge_frames, visit_frames))\n",
    "    nonvisit_frames = wedge_frames[nonvisit]\n",
    "    return visit_frames, nonvisit_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_mod = 0\n",
    "not_cache_mod = 0\n",
    "cache_infos = []\n",
    "results = {}\n",
    "for mat_file in mat_files:\n",
    "    # Load data\n",
    "    results[mat_file] = {}\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "    cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "    cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "    cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "    was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "    was_cache = np.logical_not(was_retrieval)\n",
    "    spikes = np.array(f['S'])\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        results[mat_file][cache_site] = []\n",
    "        cache_frames, noncache_frames = get_visit_frames(\n",
    "            wedges, wedge_frames, cache_site,\n",
    "            cache_frames_enter, cache_frames_exit\n",
    "            )\n",
    "        for neur in np.arange(spikes.shape[1]):\n",
    "            neur_spikes = spikes[:, neur]\n",
    "            neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "            cf = np.intersect1d(fr_frames, cache_frames)\n",
    "            ncf = np.intersect1d(fr_frames, noncache_frames)\n",
    "            combined_frames = np.concatenate([cf, ncf])\n",
    "            contexts = np.concatenate([np.ones(cf.size), np.zeros(ncf.size)])\n",
    "            cache_info = get_mutual_info(\n",
    "                contexts, neur_fr[np.isin(fr_frames, combined_frames)]\n",
    "                )\n",
    "            shuffled_info = []\n",
    "            shuffled_peak_fr = []\n",
    "            for _ in range(110):\n",
    "                shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "                shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "                shuffled_info.append(get_mutual_info(\n",
    "                    contexts, shuffled_fr[np.isin(fr_frames, combined_frames)]\n",
    "                    ))\n",
    "                shuffled_peak_fr.append(shuffled_fr.max())\n",
    "            shuffled_info = np.array(shuffled_info)\n",
    "            high_mutual_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "            cache_infos.append(cache_info)\n",
    "            if high_mutual_info:\n",
    "                cache_mod += 1\n",
    "                results[mat_file][cache_site].append(neur)\n",
    "            else:\n",
    "                not_cache_mod += 1\n",
    "with open(\"specific_visit.p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the whole visit\n",
    "num_neurs = 0\n",
    "for key in results.keys():\n",
    "    neurs = []\n",
    "    for key2 in results[key].keys():\n",
    "        neurs.extend(results[key][key2])\n",
    "    num_neurs += len(neurs)\n",
    "    print(key)\n",
    "    print(np.unique(neurs))\n",
    "    print()\n",
    "print(\"%d Total\"%num_neurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a window around the cache\n",
    "num_neurs = 0\n",
    "for key in specific_cache_results.keys():\n",
    "    neurs = []\n",
    "    for key2 in specific_cache_results[key].keys():\n",
    "        neurs.extend(specific_cache_results[key][key2])\n",
    "    num_neurs += len(neurs)\n",
    "    print(key)\n",
    "    print(np.unique(neurs))\n",
    "    print()\n",
    "print(\"%d Total\"%num_neurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a 30-frame window around the cache\n",
    "num_neurs = 0\n",
    "for key in results.keys():\n",
    "    neurs = []\n",
    "    for key2 in results[key].keys():\n",
    "        neurs.extend(results[key][key2])\n",
    "    num_neurs += len(neurs)\n",
    "    print(key)\n",
    "    print(np.unique(neurs))\n",
    "    print()\n",
    "print(\"%d Total\"%num_neurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying specific episode cells by visit window\n",
    "Looking at the entire cache/retrieval visit. Specificity for a cache at a specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visit_window_frames(\n",
    "    wedges, wedge_frames, cache_site,\n",
    "    cache_frames_enter, cache_frames_exit, cache_frames_poke\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "    cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "    cache_frames_poke = cache_frames_poke[event_idxs]\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    window = 30\n",
    "    if event_idxs.size == 1:\n",
    "        cache_frames_enter = [cache_frames_enter]\n",
    "        cache_frames_exit = [cache_frames_exit]\n",
    "        cache_frames_poke = [cache_frames_poke]\n",
    "    visit_frames = [\n",
    "        np.arange(enter, cache_frames_exit[i] + 1) for i, enter in enumerate(cache_frames_enter)\n",
    "        ]\n",
    "    visit_frames = np.concatenate(visit_frames)\n",
    "    window_frames = []\n",
    "    for i, enter in enumerate(cache_frames_enter):\n",
    "        poke = cache_frames_poke[i]\n",
    "        exit = cache_frames_exit[i]\n",
    "        prepoke_time = poke - enter\n",
    "        postpoke_time = exit - poke\n",
    "        total_time = exit - enter\n",
    "        if prepoke_time >= window and postpoke_time >= window:\n",
    "            _window_frames = np.arange(poke-window, poke+window+1)\n",
    "        elif prepoke_time < 30 and total_time > (window*2 + 1):\n",
    "            _window_frames = np.arange(enter, enter+window*2+1)\n",
    "        elif postpoke_time < 30 and total_time > (window*2 + 1):\n",
    "            _window_frames = np.arange(exit-window*2, exit+1)\n",
    "        else:\n",
    "            _window_frames = np.arange(enter, exit+1)\n",
    "        window_frames.append(_window_frames)\n",
    "        \n",
    "    if len(window_frames) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    window_frames = np.concatenate(window_frames)\n",
    "    nonvisit = np.logical_not(np.isin(wedge_frames, visit_frames))\n",
    "    nonvisit_frames = wedge_frames[nonvisit]\n",
    "    return window_frames, nonvisit_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_mod = 0\n",
    "not_cache_mod = 0\n",
    "cache_infos = []\n",
    "results = {}\n",
    "for mat_file in mat_files:\n",
    "    # Load data\n",
    "    results[mat_file] = {}\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "    cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "    cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "    cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "    was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "    was_cache = np.logical_not(was_retrieval)\n",
    "    spikes = np.array(f['S'])\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        results[mat_file][cache_site] = []\n",
    "        cache_frames, noncache_frames = get_visit_window_frames(\n",
    "            wedges, wedge_frames, cache_site,\n",
    "            cache_frames_enter, cache_frames_exit, cache_frames_poke\n",
    "            )\n",
    "        if cache_frames.size == 0:\n",
    "            results[mat_file][cache_site].append(np.nan)\n",
    "            continue \n",
    "        for neur in np.arange(spikes.shape[1]):\n",
    "            neur_spikes = spikes[:, neur]\n",
    "            neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "            cf = np.intersect1d(fr_frames, cache_frames)\n",
    "            ncf = np.intersect1d(fr_frames, noncache_frames)\n",
    "            combined_frames = np.concatenate([cf, ncf])\n",
    "            contexts = np.concatenate([np.ones(cf.size), np.zeros(ncf.size)])\n",
    "            cache_info = get_mutual_info(\n",
    "                contexts, neur_fr[np.isin(fr_frames, combined_frames)]\n",
    "                )\n",
    "            shuffled_info = []\n",
    "            shuffled_peak_fr = []\n",
    "            for _ in range(110):\n",
    "                shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "                shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "                shuffled_info.append(get_mutual_info(\n",
    "                    contexts, shuffled_fr[np.isin(fr_frames, combined_frames)]\n",
    "                    ))\n",
    "                shuffled_peak_fr.append(shuffled_fr.max())\n",
    "            shuffled_info = np.array(shuffled_info)\n",
    "            high_mutual_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "            cache_infos.append(cache_info)\n",
    "            if high_mutual_info:\n",
    "                cache_mod += 1\n",
    "                results[mat_file][cache_site].append(neur)\n",
    "            else:\n",
    "                not_cache_mod += 1\n",
    "with open(\"specific_visit.p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractedWithXY_Cleaned184713_09102019.mat\n",
      "[ 0  7 10 12 15 16 17 18 19 23 33]\n",
      "\n",
      "ExtractedWithXY_Cleaned184430_09102019.mat\n",
      "[ 7  8 11 16 43]\n",
      "\n",
      "ExtractedWithXY_Cleaned184526_09102019.mat\n",
      "[ 0  1  2  4  6  7  8  9 12 19 20 22 28 30 43]\n",
      "\n",
      "ExtractedWithXY_Cleaned184946_09102019.mat\n",
      "[ 2 18 33 34]\n",
      "\n",
      "ExtractedWithXY_Cleaned185033_09102019.mat\n",
      "[ 0  1  2 13 18 32]\n",
      "\n",
      "ExtractedWithXY_Cleaned184331_09102019.mat\n",
      "[ 4 10]\n",
      "\n",
      "ExtractedWithXY_Cleaned144233_09112019.mat\n",
      "[ 1  2  3  4  5 11 14 17 18 19 20 22 24 25 27 28 34 41 44 53]\n",
      "\n",
      "83 Total\n"
     ]
    }
   ],
   "source": [
    "# Using a 30-frame window around the cache, restricted to within-visits\n",
    "with open(\"specific-cache-40.p\", \"rb\") as f:\n",
    "    results = pickle.load(f)[\"original\"]\n",
    "num_neurs = 0\n",
    "for key in results.keys():\n",
    "    neurs = []\n",
    "    for key2 in results[key].keys():\n",
    "        neurs.extend(results[key][key2])\n",
    "    num_neurs += len(neurs)\n",
    "    print(key)\n",
    "    print(np.unique(neurs))\n",
    "    print()\n",
    "print(\"%d Total\"%num_neurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"specific-cache-40.p\", 'rb') as f:\n",
    "    cache_results = pickle.load(f)\n",
    "cache_results = cache_results[\"original\"]\n",
    "with open(\"spatial.p\", 'rb') as f:\n",
    "    spatial_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_frames(\n",
    "    window, wedges, wedge_frames,\n",
    "    cache_site, cache_sites,\n",
    "    cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_pokes = cache_frames_poke[event_idxs]\n",
    "    cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "    cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_pokes = [cache_pokes]\n",
    "        cache_frames_enter = [cache_frames_enter]\n",
    "        cache_frames_exit = [cache_frames_exit]\n",
    "    cache_frames = [np.arange(c-window, c+window+1) for c in cache_pokes]\n",
    "    cache_frames = np.concatenate(cache_frames)\n",
    "    visit_frames = [\n",
    "        np.arange(c, cache_frames_exit[i]) for i, c in enumerate(cache_frames_enter)\n",
    "        ]\n",
    "    visit_frames = np.concatenate(visit_frames)\n",
    "    noncache = np.logical_not(np.isin(wedge_frames, cache_frames))\n",
    "    nonvisit = np.logical_not(np.isin(wedge_frames, visit_frames))\n",
    "    noncache_frames = wedge_frames[np.logical_and(noncache, nonvisit)]\n",
    "    return cache_frames.astype(int), noncache_frames.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_spatial_info(mat_file, neur):\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    spikes = np.array(f['S'])\n",
    "    neur_spikes = spikes[:, neur]\n",
    "    neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "    valid_frames = np.intersect1d(fr_frames, wedge_frames)\n",
    "    spatial_info = get_mutual_info(\n",
    "        wedges[np.isin(wedge_frames, valid_frames)],\n",
    "        neur_fr[np.isin(fr_frames, valid_frames)]\n",
    "        )\n",
    "    shuffled_info = []\n",
    "    shuffled_peak_fr = []\n",
    "    for _ in range(110):\n",
    "        shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "        shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "        shuffled_info.append(get_mutual_info(\n",
    "            wedges[np.isin(wedge_frames, valid_frames)],\n",
    "            shuffled_fr[np.isin(fr_frames, valid_frames)]\n",
    "            ))\n",
    "        shuffled_peak_fr.append(shuffled_fr.max())\n",
    "    shuffled_info = np.mean(shuffled_info)\n",
    "    return spatial_info/shuffled_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_cache_info(mat_file, neur):\n",
    "    window = 40\n",
    "    cache_infos = []\n",
    "    f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "    _, wedge_frames = get_wedges(f)\n",
    "    wedges = np.array(f['whichWedge']).squeeze()\n",
    "    wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "    cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "    cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "    cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "    cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "    was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "    was_cache = np.logical_not(was_retrieval)\n",
    "    spikes = np.array(f['S'])\n",
    "    for cache_site in np.unique(cache_sites):\n",
    "        cache_frames, noncache_frames = get_cache_frames(\n",
    "            window, wedges, wedge_frames,\n",
    "            cache_site, cache_sites,\n",
    "            cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "            )\n",
    "        if cache_frames.size == 0:\n",
    "            continue\n",
    "        neur_spikes = spikes[:, neur]\n",
    "        neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "        cf = np.intersect1d(fr_frames, cache_frames)\n",
    "        ncf = np.intersect1d(fr_frames, noncache_frames)\n",
    "        combined_frames = np.concatenate([cf, ncf])\n",
    "        contexts = np.concatenate([np.ones(cf.size), np.zeros(ncf.size)])\n",
    "        cache_info = get_mutual_info(\n",
    "            contexts, neur_fr[np.isin(fr_frames, combined_frames)]\n",
    "            )\n",
    "        shuffled_info = []\n",
    "        shuffled_peak_fr = []\n",
    "        for _ in range(110):\n",
    "            shuffled_spikes = circular_shuffle(neur_spikes)\n",
    "            shuffled_fr, _ = get_fr(shuffled_spikes)\n",
    "            shuffled_info.append(get_mutual_info(\n",
    "                contexts, shuffled_fr[np.isin(fr_frames, combined_frames)]\n",
    "                ))\n",
    "            shuffled_peak_fr.append(shuffled_fr.max())\n",
    "        shuffled_info = np.array(shuffled_info)\n",
    "        high_mutual_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "        if high_mutual_info:\n",
    "            cache_infos.append(cache_info/np.mean(shuffled_info))\n",
    "    return np.mean(cache_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chingf/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/chingf/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "spatial_infos = []\n",
    "cache_infos = []\n",
    "for mat_file in mat_files:\n",
    "    spatial_cells = spatial_results[mat_file]\n",
    "    cache_cells = []\n",
    "    for key in cache_results[mat_file].keys():\n",
    "        cache_cells.extend(cache_results[mat_file][key])\n",
    "    all_cells = spatial_cells + cache_cells\n",
    "    for neur in np.unique(all_cells):\n",
    "        if neur in spatial_cells:\n",
    "            spatial_infos.append(get_normalized_spatial_info(mat_file, neur))\n",
    "        else:\n",
    "            spatial_infos.append(0)\n",
    "        if neur in cache_cells:\n",
    "            cache_infos.append(get_normalized_cache_info(mat_file, neur))\n",
    "        else:\n",
    "            cache_infos.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spatial_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAE9CAYAAAAMFgk+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwcd3nn8c/T13T3HBqNNLJly7IEduwYY2wQxGCSAA5ZCGAIARMCrBecePe1ZCFZNgTYLAtJNi8CS44N2WQdDhtCuDEYFgOOwSRsAkY+JduAjWULWbLOOTTTPX0++0dVS63RHDVH9TH9fb9eo6mu7qp6emb09K9+p7k7IiLSOxLtDkBERFpLiV9EpMco8YuI9BglfhGRHqPELyLSY5T4RUR6TKrdAUSxceNG37ZtW7vDEBHpKnfeeecRdx+dvb8rEv+2bdvYuXNnu8MQEekqZvbYXPtV1SMi0mOU+EVEeowSv4hIj1HiFxHpMUr8IiI9RolfRKTHKPGLiPSYrujHvxzjhTJ7jkwzWawwlEuzfWM/w/lMu8MSEWm7NVniHy+UuXvvGOVqnfX5DOVqnbv3jjFeKLc7NBGRtluTiX/PkWnymRT5TAozO7G958h0u0MTEWm7NZn4J4sVcunkKfty6SSTxUqbIhIR6RxrMvEP5dIUK7VT9hUrNYZy6TZFJCLSOdZk4t++sZ9CuUqhXMXdT2xv39jf7tBERNpuTSb+4XyGy7auJ5NKMFYok0kluGzrevXqERFhDXfnDJK/Er2IyGxrssQvIiLzU+IXEekxSvwiIj1GiV9EpMco8YuI9BglfhGRHqPELyLSY5T4RUR6jBK/iEiPUeIXEekxSvwiIj1GiV9EpMco8YuI9BglfhGRHqPELyLSY5T4RUR6jBK/iEiPUeIXEekxSvwiIj1GiV9EpMfEuti6mT0KHAdqQNXdd5jZCPAZYBvwKHC1u4/FGYeIiJzUihL/8939UnffET5+B3Cbu58P3BY+FhGRFmlHVc/LgRvD7RuBV7QhBhGRnhV34nfgm2Z2p5ldF+47w90PAITfN811oJldZ2Y7zWzn4cOHYw5TRKR3xFrHD1zh7vvNbBNwq5n9MOqB7n49cD3Ajh07PK4ARUR6TawlfnffH34/BNwEPAs4aGabAcLvh+KMQUREThVb4jezfjMbbGwDvwzsBm4Grglfdg3w5bhiEBGR08VZ1XMGcJOZNa7zD+7+dTP7AfBZM7sW2Au8OsYYRERkltgSv7s/Ajxtjv1HgSvjuq6IiCxMI3dFRHqMEr+ISI9R4hcR6TFK/CIiPSbuAVwiJ4wXyuw5Ms1kscJQLs32jf0M5zPtDkuk56jELy0xXihz994xytU66/MZytU6d+8dY7xQbndoIj1HiV9aYs+RafKZFPlMCjM7sb3nyHS7QxPpOUr80hKTxQq5dPKUfbl0kslipU0RifQuJX5piaFcmmKldsq+YqXGUC7dpohEepcSv7TE9o39FMpVCuUq7n5ie/vG/naHJtJzlPilJYbzGS7bup5MKsFYoUwmleCyrevVq0ekDdSdU1omSP5K9CLtphK/iEiPUeIXEekxSvwiIj1GiV9EpMcsmvjN7JVm9pCZTZjZpJkdN7PJVgQnIiKrL0qvnvcDL3P3B+MORkRE4helquegkr6IyNoRpcS/08w+A3wJKDV2uvsXY4tKRERiEyXxDwEF4Jeb9jmgxC8i0oUWTfzu/sZWBCIiIq0RpVfPFjO7ycwOmdlBM/uCmW1pRXAiIrL6ojTufgy4GTgLOBv4SrhPRES6UJTEP+ruH3P3avh1AzAac1wiIhKTKIn/iJm93syS4dfrgaNxByYiIvGIkvjfBFwNPAEcAF4V7hMRkS4UpVfPXuCqFsQiIiItMG/iN7O3u/v7zeyvCPrtn8Ld3xJrZCIiEouFSvyNaRp2tiIQERFpjXkTv7t/JdwsuPvnmp8zs1fHGpWIiMQmSuPuOyPuExGRLrBQHf+LgV8Bzjaz/9X01BBQjTswERGJx0J1/PsJ6vevAu5s2n8c+N04gxIRkfgsVMd/L3Cvmf2Du1eWewEzSxJ8gDzu7i81s+3Ap4ER4C7gDe5eXu75RURkaaLU8W8zs8+b2QNm9kjjawnXeCsnewgB/Cnw5+5+PjAGXLuEc4mIyApFnaTtbwjq9Z8PfBz4RJSTh7N4vgT4cPjYgBcAnw9fciPwiqWFLCIiKxEl8efc/TbA3P0xd38PQfKO4i+AtwP18PEGYNzdG43D+whm/BQRkRaJkvhnzCwBPGRmv21mvwpsWuwgM3spcMjdmxuGbY6XnjYqODz+OjPbaWY7Dx8+HCFMERGJIkri/x0gD7wFeAbwBuCaCMddAVxlZo8SNOa+gOAOYNjMGo3KWwh6D53G3a939x3uvmN0VLNAi4islkUTv7v/wN2n3H2fu7/R3V/p7t+LcNw73X2Lu28Dfh34lru/Dvg2wQyfEHyAfHkF8YuIyBJFWXpxR7j04l1mdl/jawXX/H3gP5vZwwR1/h9ZwblERGSJFp2WGfgk8HvALk420i6Ju98O3B5uPwI8aznnERGRlYuS+A+7+82xRyIiIi0RJfH/dzP7MHAbUGrsdPcvxhaViIjEJkrifyNwIZDmZFWPA0r8IiJdKErif5q7PzX2SEREpCWi9OP/npldFHskIiLSElFK/M8FrjGzPQR1/Aa4u18Sa2QiIhKLKIn/RbFHISIiLbNg4g/n6Pm/7n5xi+IREZGYLVjH7+51gsVYtrYoHhERiVmUqp7NwP1mdgcw3djp7lfFFpWIiMQmSuJ/b+xRiIhIyyya+N39O2Z2BvDMcNcd7n4o3rBERCQuUWbnvBq4A3g1cDXwfTN71cJHiYhIp4pS1fNfgWc2SvlmNgr8IyfXzRURkS4SZeRuYlbVztGIx4mISAeKUuL/upl9A/hU+Pg1wNfiC0lEROI0b+I3sz53L7n775nZKwmmbjDgene/qWURiojIqlqoxP+vwNPN7BPu/gY0DbOIyJqwUOLPmNk1wHPCEv8ptBCLiEh3Wijx/wfgdcAw8LJZz2khFhGRLjVv4nf37wLfNbOd7v6RFsYkIiIxijJy9yNm9hxgW/Pr3f3jMcYlIiIxWTTxm9kngCcD9wC1cLcDSvwiIl0oSj/+HcBF7u5xByMiIvGLMgJ3N3Bm3IGIiEhrRCnxbwQeCOfjLzV2aj5+EZHuFCXxvyfuIEREpHUizcffikBERKQ1Fpqr5zhB753TngLc3Ydii0pERGKz0ACuwVYGIiIiraF59UVEeowSv4hIj1HiFxHpMZESv5mda2a/FG7nzEz1/yIiXWrRxG9mv0WwsPr/CXdtAb4UZ1AiIhKfKCX+NwNXAJMA7v4QsGmxg8wsa2Z3mNm9Zna/mb033L/dzL5vZg+Z2WfMLLOSNyAiIksTJfGX3L3ceGBmKebu33/accAL3P1pwKXAi8zscuBPgT939/OBMeDapYctIiLLFSXxf8fM3gXkzOyFwOeAryx2kAemwofp8MuBFxBUHQHcCLxiyVGLiMiyRUn87wAOA7uAfw98DfiDKCc3s6SZ3QMcAm4FfgKMu3s1fMk+4OylBi0iIssXZa6eOvB34deSuHsNuNTMhoGbgJ+d62VzHWtm1wHXAWzdunWplxYRkXlE6dVzhZndamY/NrNHzGyPmT2ylIu4+zhwO3A5MBy2E0DQQ2j/PMdc7+473H3H6OjoUi4nIiILiFLV8xHgz4DnAs8kWJHrmYsdZGajYUkfM8sBvwQ8CHwbeFX4smuALy89bBERWa4o8/FPuPstyzj3ZuBGM0sSfMB81t2/amYPAJ82sz8G7ib4YBERkRZZaFrmp4eb3zazDwBf5NQVuO5a6MTufh9w2Rz7HwGetaxoRURkxRYq8X9w1uMdTduNbpkiItJlFpqP//mtDERERFojSq+eP2k00oaP14f18yIi0oWi9Op5cdgdEwB3HwN+Jb6QREQkTlF69STNrM/dS3Cia2ZfvGGJdJ7xQpk9R6aZLFYYyqXZvrGf4bzmGJTuE6XE//fAbWZ2rZm9iWDqhRvjDUuks4wXyty9d4xytc76fIZytc7de8cYL5QXP1ikw0SZsuH9ZrYLuBIw4I/c/RuxRybSQfYcmSafSZHPBP9lGt/3HJnmsq0q9Ut3iVLVQziAazmDuNpGt+WymiaLFdbP+vvJpZOMqcQvXShKr57LzewHZjZlZmUzq5nZZCuCWy7dlstqG8qlKVZqp+wrVmoM5dJtikhk+aLU8X8IeC3wEJADfhP4qziDWqnm23IzO7G958h0u0OTLrV9Yz+FcpVCuYq7n9jevrG/3aGJLFmkxdbd/WEg6e41d/8Y0NGDuyaLFXLp5Cn7cukkk8VKmyKSbjecz3DZ1vVkUgnGCmUyqQSXbV2v6kPpSlHq+Avhurj3mNn7gQNARxdzGrfljQY40G25rFyQ/JXopftFKfG/IXzdbwPTwDnAr8UZ1ErptvykRnvHd350SO0cIgIskPjD+fQvcvfH3H3G3Sfd/b3AR4GJ1oW4dLotD6iRW0TmslBVz18BfzPH/rOBdwG/EUtEq0S35ep7LiJzW6iq56nu/p3ZO8PBW5fEF5KsFjVyi8hcFirxL9QS2vGtpBrApUZuEZnbQiX+h8zstFk4zezFwJIWW2811W0H1MgtInNZqMT/u8BXzexq4M5w3w7g2cBL4w5sJVS3HWg0cu85Ms1YocxQLs0FZ/ZeI7eInGqhFbh+bGZPJWjEvTjc/R3g37v7TCuCWy7Nq3KSGrlFZLYFB3CFc/B/rEWxrJqhXJrDx0uMFcpMlaoM9KVYn88wMqAEKCISacqGbjPSn2H34+NMzVQY7EsxNVNh9+PjjPR3f+LXgCwRWak1mfiPTZe5+OxhBrJpjpdqDGTTXHz2MMemuztJqtFaRFZDpPn4u81kscLoYB+bhrIn9rl719fxq9FaRFbDvIk/XHXL53ve3Tt2ENda7b+uRmsRWQ0LlfgbXTbfHH7/RPj9dUAhtohWwfaN/dy9dwwIEmOxUqNQrnLBmevbHNnKdPoHmgbNiXSHeev4w8nZHgOucPe3u/uu8OsdwL9pXYhLt1YnaevkAVlqfxDpHlHq+PvN7Lnu/l0AM3sOHT4fP6zN/uudPCBrtdsfdPcgEp8oif9a4KNmto6gzn8CeFOsUa2CtZo4OvUDbTXbHxp3D/lMMP6iWKlx996xNXHXJtIJFu3O6e53uvvTCGbkvNTdL3X3u+IPbflU7dB6q7kYudZMFonXoonfzM4ws48An3H3CTO7yMyubUFsy7bnyDT1Ovz0WIG79o7x02MF6nWUOGK0mu0Pmk5aJF5RBnDdAHwDOCt8/GPgd+IKaDXsHy/y2NEpKrU6Q9k0lVqdx45OsX+82O7Q2ibuEb+r2aC+mncPInK6KIl/o7t/FqgDuHsVqC18SHtNzVRJmJFNB1UF2XSKhBlTM9V2h9YWrar6aiT/X7xg04rq4zu595LIWhAl8U+b2QbCwVxmdjkdvubuQDZFHZip1HB3Zio16uH+XtRtdeZrtTuuSKeIkgnfBtwMPNnM/h8wCrw61qhW6KzhHNlU0KNkcqbKQF+STYP9PTs7ZzeO+O3U3ksia8Giid/d7zSzXwQuAAz4kbsv2spmZucAHwfOJKgmut7d/9LMRoDPANuAR4Gr3X1s2e9gDts39jNeKHPOSP6Ukbu9WlXQ6SN+RaS1ovTq+Qnwm+5+v7vvdveKmX01wrmrwNvc/WeBy4E3m9lFwDuA29z9fOC28PGqUlXBqVRnLiLNolT1VIDnm9nPEay+VQbOXuwgdz8AHAi3j5vZg+FxLweeF77sRuB24PeXHPkiVFVwUieP+BWR1ouS+Avu/hozezvwz+EavPPO2jkXM9sGXAZ8Hzgj/FDA3Q+Y2aalhRzNWh25u1z6IBSRhii9egzA3d8PvIugT/+WqBcwswHgC8DvuPvkEo67zsx2mtnOw4cPRz0M0MhdEZGFREn8725suPttBDNzfijKyc0sTZD0P+nuXwx3HzSzzeHzm4FDcx3r7te7+w533zE6Ohrlcid0W/fFZlpaUUTittBCLBe6+w+Bx83s6bOeXrRx18wM+AjwoLv/WdNTNwPXAO8Lv395yVEvohu7LwI8dnSaWx94glodRvJpqjVnvFDu6YZpEVl9C9Xxvw34LeCDczznwAsWOfcVwBuAXWZ2T7jvXQQJ/7PhfD97iWFMQDd2XxwvlLn1gYOkzBgZyFCq1tl7rMDWkbyWVhSRVTVv4nf33wq/P385Jw7n77d5nr5yOeeMqhtX4NpzZJpavc7IQDacZiKYpOzYdIlUcr4fo4jI0i1U1fPKhQ5sqrPvON3YfXGyWGEkn6FUrZFNB7+WvlSCw1MlzjtjsM3RichaslBVz8sWeM6Bjk380H3dF4dyQZ3+3mNBA3RfKslksUwyQVsHWqlbrMjas1BVzxtbGUiva0wzsXWkn2PTJQ5PzZBMJHjhRWe2LdFqJSyRtSnSdJVm9hLgKUC2sc/d/zCuoHpRc/VUKmmcd8Zg20vXq72Oroh0hkUTv5n9LZAHng98GHgVcEfMcfWkTque6sZusaqaEllclAFcz3H3fwuMuft7gWcD58QblnSCqCthdcqgM43YFokmSuJvrFdYMLOzCCZt2x5fSNIposzq2UnJtptHbIu0UpTE/1UzGwY+ANxFMIf+p+MMSjpDlOmtOynZapF2kWiiLMTyR+HmF8J5+LPu3tFLL8rqWazdoZPaAbpxxLZIO0Rp3E0CLyFYMSsV7mPW/DvSozop2XbjiG2RdojSnfMrwAywi2AJRekw7ezJ0knJthtHbIu0Q5TEv8XdL4k9ElmWdg+y6rRk22ldYkU6UZTEf4uZ/bK7fzP2aFZRr/Tn7oRBVnEm2175PYq0UpRePd8DbjKzoplNmtlxM4u8klY7dFIXw7it5Z4svfR7FGmlKIn/gwSDtvLuPuTug+4+FHNcK9JJXQzjFnWQ1VJ0yoCsXvo9irRSlMT/ELDb3Ze0wHo7reVS8GxRBlktRSeVsnvp9yjSSlHq+A8At5vZLUCpsbOTu3N2UhfDuK1242ontBk09NLvUaSVoiT+PeFXJvzqeNs39vPdhw4zXqhQqdVJJxMM59M89/ylLdreLVazcbWTBmR1UldRkbVkwcQfDt4acPffa1E8q8YBDCz4h66pp2qzTipld1pXUZG1YsHE7+41M3t6q4JZLXuOTLNpMMu2DQMn9hXK1a6ZR14Dsk5Sv3yR1RelquceM7sZ+BxwojtFJ6+5O1mskEoYP3pikqlSjYG+JJvXZZmZ1fulE2lAlojELUriHwGOAi9o2tfRa+6awR2PHqNSrVOpOemk8dOxAs84t/PrhjuhcVWlbJG1LcrsnF239u50qcb+sQLr8xn6+1IUSlUOH5/hwjM7evgB0FmNqyKyNkWZnXML8FfAFQQl/e8Cb3X3fTHHtmz7J4pccOYQU6UqhXKNfF+KTUNZ9k8UFz+4zRZrXNUUBiKyUlGqej4G/APw6vDx68N9L4wrqJUynFwmxYaBE2vDUyxXmalW2xhVNAs1rs5X//+k0QGOTZf1YSAikUQZuTvq7h9z92r4dQPQ0R3iz9s0yMRMhZlKDXdnplJjYqbCeZsG2x3aohZa9WquKQzqdbj1gSc6YqRtJ+mUaSdEOlGUEv8RM3s98Knw8WsJGns71iVbhpkoVpgoVpgs1kiljC3rc1yyZbjdoUUyX+PqXPX/x6ZL1Op0xEjbTrGaPaNUtSZrUZQS/5uAq4EnCKZveFW4r2MN5zP8/PmjPOWsdWwf7ecpZ63j588f7fr/sHNNyHasUGYkf+rgql6fz2a1JnfrpHmLRFZTlF49e4GrWhCLLGKkP8OtDxykVq8zks8w0t9HMpFgpL/vlNf1+nw2q9UzqhO61orEYd7Eb2bvXuA4b1qEveO0exBUHMYLZR45PMX2Df0cmy5xrFBhYqbCz23fwJGpEoVytSNG2naC1Zp2Ql1rZa1aqKpneo4vgGuB3485rhVZi/O4N97TpqEsF25ex1PPXkc2neSOR4+RTBilau20xuBetVpTVcex1oFIJ5i3xO/uH2xsm9kg8FbgjcCnCRZn6VhrsaTW/J6Oz1T40RPH6UslSAB9qSSFcrXnE37Dak070WnzFomslsVm5xwB/jPwOuBG4OnuPtaKwFZiKJfm8PESY4UyU6UqA31Blc/IQPcmxebqi/3jRbLpJOAMZtOqe55DlGknFuuxo3mLZK1aqI7/A8ArgeuBp7r7VMuiWqGR/gzf3H2ASq2OmeHupJMJfv3nzm13aMvWXPqcmqmSSRmlap1zNwTVF3Pd0agr4vyitgNp3iJZixaq438bcBbwB8D+cKH1rlhs/bGj02TSSTKpJGBkUkky6SSPHe3eOv7mgV116tQdLjhziMFsUN88u+5ZXREXthbbgUSiWqiOP0of/3mZ2UeBlwKH3P3icN8I8BlgG/AocHUcVUcPHzrOGYNZcs29OspVHj50nF/4mU2rfbmWaZQ+G6X/ZCK4m5mr7lldERe2FtuBRKJaUXJfxA3Ai2btewdwm7ufD9wWPl51jnH6mlse7u9+C03r0KCFyhemHjvSy6JM2bAs7v5PZrZt1u6XA88Lt28EbieGrqHnbxrggf0TmBl9qSSlao3JmQoXnbVutS/VNovVPXfSEoqdSD12pJPF3T4XZ4l/Lme4+wGA8Hss9S6XbBlmy/o8tbozUSxTqztb1ue7Zq6e1bBafdnXqih3TSLt0Ir2udhK/CtlZtcB1wFs3bp1SccO5zM89/zRnu7Roq6Ii1OPHelErWifa3XiP2hmm939gJltBg7N90J3v56gKyk7duyYXWG/KP2n1s9ATqcuvp2vFR0PWl3VczNwTbh9DfDlFl9fpGepi293aEXHg9gSv5l9CvhX4AIz22dm1wLvA15oZg8RrOD1vriuL6tDC5qsHRq70B1a0T4XZ6+e187z1JVxXbOZbmlXbi3OctrLNHahO7Sifa5jG3dXQglrYVE/FOdrZLpv3ziD2bQ+VLuMuvh2j7jb51pdx98SuqWd31LqeecaBFat1bln77jqibuQuvhKw5pM/Bq1Or+lfCjO1ci05+g0I/0Zfah2IY1dkIY1WdWjW9r5LaWed67RrcemSjzj3JFIx0vnURdfgTWa+DUc/6TZ9flmRP5QnKuR6dKt60klT71R1IeqSHdZk4l/OJ/hSaMDfO8nRzl8fIbRwSyXP3lDz93SztXIPVms4FTYNJiN9KE4u4TYOCfoQ7UV1DtN4rAm6/gbC5Nv29jPL/zMJrZt7OeRw1M91wA5V33+6GCWdbn0sut5VU/cOhpwJXFZkyV+zUUfmK8+f6ZS47Ktyy+hq564NfR3LHFZkyV+9eoJaM757qa/Y4nLmkz8SngB9dvubvo7lrisycSvhBdQfXx309+xxGVN1vFrLvqTVB/fvfR3LHFZk4kflPBkbdDfscRhTVb1iIjI/JT4RUR6jBK/iEiPUeIXEekxSvwiIj1GiV9EpMco8YuI9BglfhGRHqPELyLSY5T4RUR6jBK/iEiPUeIXEekxSvwiIj1GiV9EpMco8YuI9BglfhGRHqPELyLSY5T4RUR6jBK/iEiPUeIXEekxSvwiIj1GiV9EpMek2nFRM3sR8JdAEviwu7+vHXG00q5949yy+wkOThRZl08xOpjl0PESR46XwZ3pcpXHjhY4OlWmXKsCUK5ANTw+AWwZznLZucM8fHCKPUenKNeC/ekkWCKJeY1UKkkulWIwm2K4P006kQRz0gmjL5WkVK1TqFRwN/pSCeqAAalkglwywWSpwkyljgNGHSdBOmHk+1KkkwlwYzCXZPvGfoayKX78xBQPPDHBockylVqNcrUOZgxmUpy7sZ9zN+Rxd0rVOn2pJJuHc1yyZR2XbBlmoljhWw8e5P7HJ5ipOmeu6+Os4SxnDOU4azjH9o39DOczPHZ0mu/95Ch7jxVwYNuGPGeuywLgDkO5NKmE8cD+yVNec/4ZgyfOMV4os+fINPvHi0zNVBnIpk5cA2DPkWkmixWGcmlG+jMcmy4zWawwXa6y58g0j48V6Esneea2EZ7z5I0M5zMnfreNczeOn33NyWIFM06Jd67rNo6bz3ihzH37xnno0BSGc96mQS7ZMrzgMYvFuFSddp44r9GKGNvF3L21FzRLAj8GXgjsA34AvNbdH5jvmB07dvjOnTtbFOHq27VvnI/88yMM59L0pRPc9/gk+8YK/MymQSaKZY5Nldk/WSThUKgtfj4jSPjzvTRF8GGQSBh96QQDmTR1d4rVKplkCsdJmjFVqtLfl6ZerzHQl+bQVInBvhTVWo1q3Zmp1FmXz1CtOjWcbDrBSD5DOplgKJtk31iRusNUqcz0TI1C+CmVTkAy/OrvS7NlOE8dWJ9PMzqY5cyhvhMJfWqmSrFSo1Krc3Byhq0b+rnwzCEuPHOIRAI2DvTxrQcPkk4lODpVolZzJktVNg70MdKf5qlnD3Nkqsy3f3iQrSP9TJcr1GrBB83lT97IUC7Fk0YHeOTwFPU6PHZsmgRQd+fcDQMUKlUMGB3MkksnOXy8xO7Hx7n47GGq9Tr/9779TBQrnDc6QCJhjBfL7Dh3hH9z8eYTyf3uvWPkMyly6STFSo1CuXrimvlMimqtzq7Hx3GMS85eRyqZ4NDxmVOu2zjusq3r50wu44Uy333oMPvGCgxl04AxMVNhy/ocP3/+6KIfGHPFON+1uuU8cV6jFTG2gpnd6e47Zu9vR1XPs4CH3f0Rdy8DnwZe3oY4WuaW3U8wnEszMpBlcqZKpVpnIJvmoUPHGehLMz5TJWFQrke7BXPA5vjNWdPzdaDmjnuCUq1GpV7HSFCq1kgnEsxU66RTCWYqFZKJBOOFMqmEMVOt4SSo1CCbSTJVqmIJSBpUKk6l7gzl0jxyuEi9DlMzNUo1cEuQABIGiQTUHZwEM+U6h6fLrMulMTNq9TqVmnPvTyc4Ol0BM/r7gucGsxmmSlWmS1XGCmXymRS37H6Cdbk05WqdXDrFyECWWt05MlViXS7DgYkZHj50nOFcmoPHZ8ilg5/zYDbNw4eOk8+k+NzUuKIAAA5gSURBVN5PjpLPpBgrlMmlU6zL95ELH08UK4wXKuQzKcyMsUIQ61ihzO7HJzAzRvqzFCo1BrMZ1uf6eOTwNHuOTANBiT2fSZ04vrHduGY+k+LAxAzrchmGw3jzmdRp1228tnHe2fYcmWa8UGFdLkMukyaXSTGcyzBRrMx7TPOxc8W42HGdfp44r9GKGNupHYn/bOCnTY/3hftOYWbXmdlOM9t5+PDhlgUXh6B6Jw3ATKVOqVZjMJOgUK7Rl05QrtUwoLaEmy+vz7GPIPk7UKsHybfuTrVep1Z3DKdcqwcfMrU6KaBcg5QZM9U6KYNy1XHq1Op1MgmjUq1TD+8Ka16nWq3Tl0oEJWVzyvU6Xnfq9fqJIOr14PqE156p1OhLJajVnWoNqjVnolimUg3uLFIJo1R18pkkM5UalZozVaqRSyc5OFFkMJumUK6RTp38cy2Wa/Slgg+msUKZdfk0kzNV0qng4y/flwwTfZLDx2fIpZNMlYI4gBPHVqtOpXbyhzlVqjKYTTNVqjFWKGNANm3MVPzEeadKFSaLFQAmixVy6eQpv4fmazbO2ZdK0pdKMFUK7tNmX7dxXOO8s00WK1RqQXVZQ18qQbXq8x7TfOxcMS52XKefJ85rtCLGdmpH4rc59p2W8tz9enff4e47RkdHWxBWfM5Yl2OiEPzBZNMJ+pJJjpfr5DNJSpU6mWQSJyhVRzVfib+R/JOJsPRtRiqRIJkwHCOTTFB3yCQTVIFMEqruZFMJqg6ZlGEkSCYSlOtOOpUgEVZQJy1BKpWgVK2TT6dwNzKJBJYwEonEiSASYTUP4bWz6aBtIZkwUklIJY11uQzpVJJUwqjWnb6UUSjXyKaTpJPGQF9we33GuhzHZyrkM0kq1ZOJMpdJUqrWGOhLsT6fYaJQYSibolIN/pQKpRrr8xmKlRqjg1mKlRoDfUEcwIljUykL2i5CA30pjs9UGOhLsj6fwYGZipNN24nzDvSlGcoFH+RDuTTFyqmVbs3XbJyzVK1RqtYZ6AuSyezrNo5rnHe2oVyadDK4Y2soVeukUjbvMc3HzhXjYsd1+nnivEYrYmyndiT+fcA5TY+3APvbEEfLvPjiMxkvVjg2NcNQNkU6lWBqpsL5mwaZKlUYzqaCZJw42Zi7EGP+En/j+QSQNMOsTl8ySTqRwAlKjJV6nWwqQaVaJ5tOU6vXGc5nqNadbCqJUSedhJlykBy9HtyNpNNGOmFMFis8aTRHIgED2SR9STCvUye8y6gHHzpGnWwmwWh/UCXh7iQTCdJJ42nnrGNDfzpo2C4Fzx2fKTPQl6I/TOaFcpUXX3wmE8UKmVSCYqXKsakZkglj40AfE8Uym9dlOW/TIOPFCmcMZilWgp/z8ZkK520apFCucvmTN1AoV8MPgioThRLF8PG6XJrhfJpCuYq7Bx8ixQrr8xkuPnsd7s6x6Rny6STHZ8qMFUs8abT/ROPs9o39FMrVE8c3thvXLJSrbF6XZaJYZjyMt1Cunnbdxmsb550taFhMM1EsUyxXKJarjBeDaqn5jmk+dq4YFzuu088T5zVaEWM7taNxN0XQuHsl8DhB4+5vuPv98x3T7Y27oF496tXDKfGqV4969bTCfI27LU/8YTC/AvwFQXfOj7r7/1jo9Wsh8YuItNp8ib8t/fjd/WvA19pxbRGRXqeRuyIiPUaJX0Skxyjxi4j0GCV+EZEeo8QvItJjlPhFRHqMEr+ISI9pywCupTKzw8Bjyzx8I3BkFcNpJcXeHoq9PRT76jvX3U+b7KwrEv9KmNnOuUaudQPF3h6KvT0Ue+uoqkdEpMco8YuI9JheSPzXtzuAFVDs7aHY20Oxt8iar+MXEZFT9UKJX0REmqzpxG9mLzKzH5nZw2b2jnbHE5WZnWNm3zazB83sfjN7a7tjWgozS5rZ3Wb21XbHslRmNmxmnzezH4Y//2e3O6aozOx3w7+X3Wb2KTPLtjum+ZjZR83skJntbto3Yma3mtlD4ff17YxxPvPE/oHwb+Y+M7vJzIbbGeNi1mziN7Mk8NfAi4GLgNea2UXtjSqyKvA2d/9Z4HLgzV0UO8BbgQfbHcQy/SXwdXe/EHgaXfI+zOxs4C3ADne/mGCRo19vb1QLugF40ax97wBuc/fzgdvCx53oBk6P/VbgYne/hGCFwXe2OqilWLOJH3gW8LC7P+LuZeDTwMvbHFMk7n7A3e8Kt48TJJ+z2xtVNGa2BXgJ8OF2x7JUZjYE/ALwEQB3L7v7eHujWpIUkAuXN83TwWtZu/s/Acdm7X45cGO4fSPwipYGFdFcsbv7N929sVLq9wjWEu9Yaznxnw38tOnxProkeTYzs23AZcD32xtJZH8BvB2YYzn4jvck4DDwsbCq6sNm1hWra7v748D/BPYCB4AJd/9me6NasjPc/QAEhR9gU5vjWa43Abe0O4iFrOXEb3Ps66ouTGY2AHwB+B13n2x3PIsxs5cCh9z9znbHskwp4OnA37j7ZcA0nVvdcIqwPvzlwHbgLKDfzF7f3qh6j5n9V4Kq2k+2O5aFrOXEvw84p+nxFjr41nc2M0sTJP1PuvsX2x1PRFcAV5nZowRVay8ws79vb0hLsg/Y5+6Nu6vPE3wQdINfAva4+2F3rwBfBJ7T5piW6qCZbQYIvx9qczxLYmbXAC8FXucd3k9+LSf+HwDnm9l2M8sQNHTd3OaYIjEzI6hnftDd/6zd8UTl7u909y3uvo3g5/0td++aUqe7PwH81MwuCHddCTzQxpCWYi9wuZnlw7+fK+mShukmNwPXhNvXAF9uYyxLYmYvAn4fuMrdC+2OZzFrNvGHDS2/DXyD4D/AZ939/vZGFdkVwBsISsz3hF+/0u6gesR/Aj5pZvcBlwJ/0uZ4IgnvUj4P3AXsIvi/3bGjSc3sU8C/AheY2T4zuxZ4H/BCM3sIeGH4uOPME/uHgEHg1vD/69+2NchFaOSuiEiPWbMlfhERmZsSv4hIj1HiFxHpMUr8IiI9RolfRKTHKPHLKczMzeyDTY//i5m9p8Ux3GBmrwq3P7zSCerMbFvzTIpN+xNm9r/C2Sx3mdkPzGz7Mq/xiuY4zewPzeyXFjnmxPuMsn/Wa/rM7B/DroOvWU7My2Fm75r1+F9adW1ZPUr8MlsJeKWZbVzOweEEYavG3X/T3eMaRPUagukNLnH3pwK/Cix3UrZXEMwCC4C7v9vd/3HlIc7rMiDt7pe6+2eiHBDOWLtSpyR+d++20cGCEr+crkow8Od3Zz9hZuea2W3hnOO3mdnWcP8NZvZnZvZt4E/N7D1mdqOZfdPMHjWzV5rZ+8NS9dfD6Sgws3eHpezdZnZ9OOJ09jVvN7MdZnZV02C2H5nZnvD5Z5jZd8zsTjP7RtOQ/2eY2b1m9q/Am+d5r5uBA+5eB3D3fe4+Fh4/ZWYfNLO7wvc6Gu7/rTDme83sC+FI2ecAVwEfCON78qy7lkXf53zCn997wzh2mdmFZrYJ+Hvg0qbrXWnBxHK7LJgvvq/p+Heb2XeBV4c/zz83s3+yYL2BZ5rZFy2YA/+Pm677pfBner+ZXRfuex/B7J/3mNknGz+n8LtZMCd94+7pNeH+54XXbKxx8MmlvH+JibvrS18nvoApYAh4FFgH/BfgPeFzXwGuCbffBHwp3L4B+CqQDB+/B/gukCaY074AvDh87ibgFeH2SNN1PwG8rOl8rwq3byeYY745xs8SJPM08C/AaLj/NcBHw+37gF8Mtz8A7J7jvW4J3+c9wAeBy5qec4I5VwDeDXwo3N7Q9Jo/Bv7T7JjneA+Lvs9ZcTUf+2jTNf4j8OFw+3nAV8PtLMFMtD8TPv44wcR+jePf3nTu24E/DbffSjB/1Wagj2Cuog3NMQM5YHfT/qnZfy/h918jmJM+CZxBMIXE5jDOifBnnSAY8frcdv+d9/qXSvxyGg9mAv04wcIezZ4N/EO4/QnguU3Pfc7da02Pb/FgsrBdBMng6+H+XcC2cPv5ZvZ9M9sFvAB4ymKxmdnbgaK7/zVwAXAx4TB54A+ALWa2Dhh29+80xTrX+9wXnuOdBNNI32ZmV4ZP14FGFcrfN73Xi83sn8OYXxcl5uW8z1kak/TdycmfXbMLCCZo+3H4+EaCdQUaZlcFNeas2gXc78H6DyXgEU5ObPgWM7uXYG75c4DzF4nxucCn3L3m7geB7wDPDJ+7w4O7qTrBh+xc70FaaFXrY2VN+QuCeV8+tsBrmuf7mJ71XAnA3etmVvGwWEiQUFMWLAv4vwlK8z+1oAF5waUCw6T8ak4mNSNIXM+e9bphIk7BHSa8W4BbzOwgQV39bXO9NPx+A8Edy71m9u8ISrQLxbzk9zmHUvi9xtz/ZxerOpnzd0Pwuyg17W/8bp5HMNvns929YGa3s3jMC8XQfI353oO0kEr8Mid3P0ZQpXJt0+5/4eRyfq8jqM5ZrkYiOWLBugOL9WI5lyCBXu3uxXD3j4BRC9fFNbO0mT3Fg1WzJsysUUp/3TznfLqZnRVuJ4BLgMfCpxNNMf0GJ9/rIHAgbKdoPu/x8LkVvc9l+iGwzczOCx+/gaDEvVzrgLEw6V9IsPxnQyV877P9E/AaC9ZbHiX4cL5jBTFIjJT4ZSEfBJp797wFeKMFM1e+gaCOeFnC5Px3BNUNXyKYRnsh/w7YANwUNi5+zYMlNV9F0KB8L0E1QqOXyRuBvw4bd4tznZBghaevWNDV8z6Chu0Phc9NA08xszsJqmf+MNz/3whWQ7uVIOE2fBr4vbCB9ckreJ9L5u4zBO/3c2F1Uh1YyeyQXyco+d8H/BFBdU/D9cB9jcbdJjcR/AzvBb5F0K7wxApikBhpdk6ROZjZlLsPtDsOkTioxC8i0mNU4hcR6TEq8YuI9BglfhGRHqPELyLSY5T4RUR6jBK/iEiPUeIXEekx/x/9ZvkkJT+UlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(spatial_infos, cache_infos, alpha=0.2)\n",
    "plt.xlabel(\"Normalized Spatial Information\")\n",
    "plt.ylabel(\"Normalized Cache Information\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells = spatial_cells + cache_cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
