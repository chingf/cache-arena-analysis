{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "from scipy.io import loadmat\n",
    "from scipy import optimize\n",
    "from math import pi, log2\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files = [m for m in os.listdir(\"data\") if m.endswith('mat')]\n",
    "session_list = pd.read_excel('data/CacheRetrieveSessionList.xlsx', index_col=0)\n",
    "fps = 20\n",
    "cmap = cm.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def estimate_center(x, y):\n",
    "    method_2 = \"leastsq\"\n",
    "\n",
    "    def calc_R(xc, yc):\n",
    "        \"\"\" calculate the distance of each 2D points from the center (xc, yc) \"\"\"\n",
    "        return np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "\n",
    "    def f_2(c):\n",
    "        \"\"\" calculate the algebraic distance between the data points and the mean circle centered at c=(xc, yc) \"\"\"\n",
    "        Ri = calc_R(*c)\n",
    "        return Ri - Ri.mean()\n",
    "\n",
    "    center_estimate = np.mean(x), np.mean(y)\n",
    "    center_2, ier = optimize.leastsq(f_2, center_estimate)\n",
    "    return center_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_xy(f, in_bound=True):\n",
    "    x = np.squeeze(np.array(f['X']))\n",
    "    y = np.squeeze(np.array(f['Y']))\n",
    "    x_c, y_c = estimate_center(x, y)\n",
    "    x -= x_c; y -= y_c\n",
    "    length = np.sqrt(np.square(x) + np.square(y))\n",
    "    frames = np.arange(x.size)\n",
    "    if in_bound:\n",
    "        oob = np.logical_or(length <= 145, length >= 215)\n",
    "        x = x[np.logical_not(oob)]\n",
    "        y = y[np.logical_not(oob)]\n",
    "        frames = frames[np.logical_not(oob)]\n",
    "    return x, y, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_theta(f):\n",
    "    x, y, frames = get_xy(f, in_bound=True)\n",
    "    theta = np.arctan2(y, x)\n",
    "    theta = np.mod(theta, 2*pi)\n",
    "    boundaries = np.linspace(0, 2*pi, 16, endpoint=False)\n",
    "    boundaries = np.append(boundaries, [2*pi])\n",
    "    theta = np.digitize(theta, boundaries)\n",
    "    return theta, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_velocity(f):\n",
    "    x, y, frames = get_xy(f, in_bound=False)\n",
    "    delta_x = x[1:] - x[:-1]\n",
    "    delta_y = y[1:] - y[:-1]\n",
    "    frames = frames[1:]\n",
    "    velocity = np.sqrt(np.square(delta_x) + np.square(delta_y)) # pixels/frame\n",
    "    velocity = velocity*fps # pixels/s\n",
    "    smoothing_kernel = np.ones(fps)/fps\n",
    "    velocity = np.convolve(velocity, smoothing_kernel, \"valid\")\n",
    "    frames = frames[:velocity.size]\n",
    "    return velocity, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wedges(f):\n",
    "    x, y, frames = get_xy(f, in_bound=True)\n",
    "    theta = np.mod(np.arctan2(y, x), 2*pi)\n",
    "    boundaries = np.linspace(0, 2*pi, 16, endpoint=False)\n",
    "    boundaries = np.append(boundaries, [2*pi])\n",
    "    wedges = np.digitize(theta, boundaries)\n",
    "    wedges = np.mod(16-wedges, 16) + 1\n",
    "    return wedges, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fr(spikes):\n",
    "    smoothing_kernel = np.ones(fps+1)/(fps+1) # One sec smoothing\n",
    "    fr = np.convolve(spikes, smoothing_kernel, \"valid\")\n",
    "    fr_frames = np.arange(spikes.size)[\n",
    "        smoothing_kernel.size//2:-smoothing_kernel.size//2+1\n",
    "        ]\n",
    "    return fr, fr_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shuffle(spikes):\n",
    "    spikes = spikes.copy()\n",
    "    shift = np.random.choice(np.arange(1, spikes.size))\n",
    "    return np.roll(spikes, shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating cache index matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_index(cache_frames, noncache_frames, neur_fr, percentile=0.8):\n",
    "    noncache_frs = []\n",
    "    cache_fr = np.mean(neur_fr[cache_frames])\n",
    "    for nc in noncache_frames:\n",
    "        noncache_fr = np.sort(neur_fr[nc])\n",
    "        noncache_fr = noncache_fr[int(noncache_fr.size*percentile):]\n",
    "        noncache_fr = np.mean(noncache_fr)\n",
    "        noncache_frs.append(noncache_fr)\n",
    "    return np.sum(noncache_frs < cache_fr)/len(noncache_frs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_index_shuffled(cache_frames, noncache_frames, neur_fr, percentile=0.8):\n",
    "    # EpisodeIndex(ni,ei) = sum(FR_othervisits<FR_episodei)/length(FR_othervisits)\n",
    "    relevant_frames = [cache_frames]\n",
    "    for nc in noncache_frames:\n",
    "        relevant_frames.append(nc)\n",
    "    relevant_frames = np.concatenate(relevant_frames)\n",
    "    np.random.shuffle(relevant_frames)\n",
    "    shuff_cache_frames = relevant_frames[:cache_frames.size]\n",
    "    idx = cache_frames.size\n",
    "    shuff_noncache_frames = []\n",
    "    for nc in noncache_frames:\n",
    "        shuff_nc = relevant_frames[idx:idx+nc.size]\n",
    "        idx += nc.size\n",
    "        shuff_noncache_frames.append(shuff_nc)\n",
    "    return get_cache_index(\n",
    "        shuff_cache_frames, shuff_noncache_frames, neur_fr, percentile\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_frames(\n",
    "    window, wedges, wedge_frames,\n",
    "    cache_site_idx, cache_sites,\n",
    "    cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    cache_site = cache_sites[cache_site_idx]\n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_poke = cache_frames_poke[cache_site_idx]\n",
    "    cache_enter = cache_frames_enter[cache_site_idx]\n",
    "    cache_exit = cache_frames_exit[cache_site_idx]\n",
    "    cache_frames = np.arange(cache_poke-window, cache_poke+window+1)\n",
    "    all_cache_exit = cache_frames_exit[cache_sites==cache_site]\n",
    "    all_cache_enter = cache_frames_enter[cache_sites==cache_site]\n",
    "    visit_frames = [\n",
    "        np.arange(c, all_cache_exit[i]) for i, c in enumerate(all_cache_enter)\n",
    "        ]\n",
    "    visit_frames = np.concatenate(visit_frames)\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    wedge_frames = wedge_frames[np.logical_not(np.isin(wedge_frames, visit_frames))]\n",
    "    wedge_frames = np.split(\n",
    "        wedge_frames, np.where(np.diff(wedge_frames) != 1)[0]+1\n",
    "        )\n",
    "    return cache_frames, wedge_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_specific_cache(find_func, window):\n",
    "    results = {}\n",
    "    for mat_file in mat_files:\n",
    "        f = h5py.File(\"data/\" + mat_file, 'r')\n",
    "        _, wedge_frames = get_wedges(f)\n",
    "        wedges = np.array(f['whichWedge']).squeeze()\n",
    "        wedges = wedges[np.isin(np.arange(wedges.size), wedge_frames)]\n",
    "        cache_sites = np.array(f['CacheSites']).squeeze()\n",
    "        cache_frames_poke = np.array(f['CacheFrames']).squeeze().astype(int) - 1\n",
    "        cache_frames_enter = np.array(f['CacheFramesEnter']).squeeze().astype(int) - 1\n",
    "        cache_frames_exit = np.array(f['CacheFramesExit']).squeeze().astype(int) - 1\n",
    "        was_retrieval = np.array(f['ThisWasRetrieval']).squeeze().astype(bool)\n",
    "        spikes = np.array(f['S'])\n",
    "        results[mat_file] = np.zeros((spikes.shape[1], cache_sites.size))\n",
    "        for cache_site_idx in range(len(cache_sites)):\n",
    "            cache_frames, noncache_frames = find_func(\n",
    "                window, wedges, wedge_frames,\n",
    "                cache_site_idx, cache_sites,\n",
    "                cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "                )\n",
    "            for neur in np.arange(spikes.shape[1]):\n",
    "                neur_spikes = spikes[:, neur]\n",
    "                neur_fr, fr_frames = get_fr(neur_spikes)\n",
    "                cf = np.argwhere(np.isin(fr_frames, cache_frames))\n",
    "                ncf = [np.argwhere(np.isin(fr_frames, ncf)) for ncf in noncache_frames]\n",
    "                cache_info = get_cache_index(cf, ncf, neur_fr)\n",
    "                shuffled_info = []\n",
    "                shuffled_peak_fr = []\n",
    "                for _ in range(110):\n",
    "                    shuffled_info.append(\n",
    "                        get_cache_index_shuffled(cf, ncf, neur_fr)\n",
    "                        )\n",
    "                shuffled_info = np.array(shuffled_info)\n",
    "                high_cache_info = np.sum(shuffled_info < cache_info) > 0.99*shuffled_info.size\n",
    "                if high_cache_info:\n",
    "                    results[mat_file][neur, cache_site_idx] = cache_info\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = find_specific_cache(get_cache_frames, window=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractedWithXY_Cleaned184713_09102019.mat\n",
      "[ 0  1  4  5  6  7  8  9 13 14 15 16 17 18 21 22 23 25 29 32 33 34 37 38\n",
      " 39 41]\n",
      "\n",
      "ExtractedWithXY_Cleaned184430_09102019.mat\n",
      "[ 5  6  7  8  9 10 11 13 14 17 20 23 24 25 27 29 30 31 32 33 46 48]\n",
      "\n",
      "ExtractedWithXY_Cleaned184526_09102019.mat\n",
      "[ 3  4  5  7  8 11 13 15 17 19 20 21 22 23 28 29 31 34 35 37 38 39 42 43\n",
      " 45]\n",
      "\n",
      "ExtractedWithXY_Cleaned184946_09102019.mat\n",
      "[ 3  5  6  8 10 14 15 17 18 19 20 21 22 27 28 29 30 31 32 33 34 35 36 37\n",
      " 38 40 41 44 46 47 48 49 50 51 52 53 54 56 61]\n",
      "\n",
      "ExtractedWithXY_Cleaned185033_09102019.mat\n",
      "[ 0  2  5  7 10 11 12 16 17 18 19 20 21 22 24 26 27 28 29 31 32 35 36 38\n",
      " 39 40 41 42 43 44 46 47 48 49 50]\n",
      "\n",
      "ExtractedWithXY_Cleaned184331_09102019.mat\n",
      "[ 6  7  9 11 14 18 23 24 26 27 29 31 32 33 34 36 38 39 40 43]\n",
      "\n",
      "ExtractedWithXY_Cleaned144233_09112019.mat\n",
      "[ 2  7  8  9 11 12 13 14 18 19 20 21 22 23 24 27 29 30 31 32 33 34 36 38\n",
      " 41 44 45 46 49 50 51 53]\n",
      "\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "num_neurs = 0\n",
    "for key in results.keys():\n",
    "    print(key)\n",
    "    cache_idx_matrix = results[key]\n",
    "    sig_neurs = np.mean(cache_idx_matrix, axis=1)\n",
    "    print(np.argwhere(sig_neurs > 0).squeeze())\n",
    "    print()\n",
    "    num_neurs += np.sum(sig_neurs>0)\n",
    "print(num_neurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating cache index matrix with visit frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visit_frames(\n",
    "    window, wedges, wedge_frames,\n",
    "    cache_site, cache_sites,\n",
    "    cache_frames_poke, cache_frames_enter, cache_frames_exit\n",
    "    ):\n",
    "    \n",
    "    event_idxs = np.argwhere(cache_sites == cache_site).squeeze()\n",
    "    cache_frames_enter = cache_frames_enter[event_idxs]\n",
    "    cache_frames_exit = cache_frames_exit[event_idxs]\n",
    "    cache_frames_poke = cache_frames_poke[event_idxs]\n",
    "    wedge_frames = wedge_frames[wedges == cache_site]\n",
    "    if event_idxs.size == 1:\n",
    "        cache_frames_enter = [cache_frames_enter]\n",
    "        cache_frames_exit = [cache_frames_exit]\n",
    "        cache_frames_poke = [cache_frames_poke]\n",
    "    visit_frames = [\n",
    "        np.arange(enter, cache_frames_exit[i] + 1) for i, enter in enumerate(cache_frames_enter)\n",
    "        ]\n",
    "    visit_frames = np.concatenate(visit_frames)\n",
    "    window_frames = []\n",
    "    for i, enter in enumerate(cache_frames_enter):\n",
    "        poke = cache_frames_poke[i]\n",
    "        exit = cache_frames_exit[i]\n",
    "        prepoke_time = poke - enter\n",
    "        postpoke_time = exit - poke\n",
    "        total_time = exit - enter\n",
    "        if prepoke_time >= window and postpoke_time >= window:\n",
    "            _window_frames = np.arange(poke-window, poke+window+1)\n",
    "        elif prepoke_time < 30 and total_time > (window*2 + 1):\n",
    "            _window_frames = np.arange(enter, enter+window*2+1)\n",
    "        elif postpoke_time < 30 and total_time > (window*2 + 1):\n",
    "            _window_frames = np.arange(exit-window*2, exit+1)\n",
    "        else:\n",
    "            _window_frames = np.arange(enter, exit+1)\n",
    "        window_frames.append(_window_frames)\n",
    "    if len(window_frames) == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    window_frames = np.concatenate(window_frames)\n",
    "    nonvisit = np.logical_not(np.isin(wedge_frames, visit_frames))\n",
    "    nonvisit_frames = wedge_frames[nonvisit]\n",
    "    return window_frames, nonvisit_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-71-1567a5d62fd7>(6)get_cache_index()\n",
      "-> return np.sum(noncache_fr < mean_cache_fr)/noncache_fr.size\n",
      "(Pdb) l\n",
      "  1  \tdef get_cache_index(cache_frames, noncache_frames, neur_fr, percentile=0.95):\n",
      "  2  \t    mean_cache_fr = np.mean(neur_fr[cache_frames])\n",
      "  3  \t    noncache_fr = np.sort(neur_fr[noncache_frames])\n",
      "  4  \t    noncache_fr = noncache_fr[int(noncache_fr.size*percentile):]\n",
      "  5  \t    import pdb; pdb.set_trace()\n",
      "  6  ->\t    return np.sum(noncache_fr < mean_cache_fr)/noncache_fr.size\n",
      "[EOF]\n",
      "(Pdb) noncache_fr.size\n",
      "139\n",
      "(Pdb) cache_frames.shape\n",
      "(124,)\n",
      "(Pdb) c\n",
      "> <ipython-input-71-1567a5d62fd7>(6)get_cache_index()\n",
      "-> return np.sum(noncache_fr < mean_cache_fr)/noncache_fr.size\n",
      "(Pdb) noncache_fr.siz\n",
      "*** AttributeError: 'numpy.ndarray' object has no attribute 'siz'\n",
      "(Pdb) noncache_fr.size\n",
      "139\n",
      "(Pdb) exit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-c74c5904326c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_specific_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_visit_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-01a6c852dea3>\u001b[0m in \u001b[0;36mfind_specific_cache\u001b[0;34m(find_func, window)\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mshuffled_ncf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_contexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     shuffled_info.append(\n\u001b[0;32m---> 42\u001b[0;31m                         \u001b[0mget_cache_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_cf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_ncf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneur_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                         )\n\u001b[1;32m     44\u001b[0m                 \u001b[0mshuffled_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-1567a5d62fd7>\u001b[0m in \u001b[0;36mget_cache_index\u001b[0;34m(cache_frames, noncache_frames, neur_fr, percentile)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnoncache_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoncache_fr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoncache_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoncache_fr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmean_cache_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnoncache_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-1567a5d62fd7>\u001b[0m in \u001b[0;36mget_cache_index\u001b[0;34m(cache_frames, noncache_frames, neur_fr, percentile)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnoncache_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoncache_fr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoncache_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoncache_fr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmean_cache_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnoncache_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = find_specific_cache(get_visit_frames, window=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractedWithXY_Cleaned184713_09102019.mat\n",
      "[ 1  4  5  7  8 14 15 18 21 22 23 25 26 27 29 37 38]\n",
      "\n",
      "ExtractedWithXY_Cleaned184430_09102019.mat\n",
      "[ 8  9 10 13 23 24 25 27 30 33 36 39 46]\n",
      "\n",
      "ExtractedWithXY_Cleaned184526_09102019.mat\n",
      "[ 3  4  5  8 15 17 20 21 23 29 34 35 38 39 42 43]\n",
      "\n",
      "ExtractedWithXY_Cleaned184946_09102019.mat\n",
      "[17 18 27 28 29 31 36 37 38 46 48 49 50 53]\n",
      "\n",
      "ExtractedWithXY_Cleaned185033_09102019.mat\n",
      "[ 0  7 10 11 17 18 19 20 21 22 24 27 28 29 31 32 35 39 40 42 44 46 47 49\n",
      " 50]\n",
      "\n",
      "ExtractedWithXY_Cleaned184331_09102019.mat\n",
      "[14 18 32 34 36 37 38 40 43]\n",
      "\n",
      "ExtractedWithXY_Cleaned144233_09112019.mat\n",
      "[ 9 19 22 27 30 32 33 34 36 44 45 46 53]\n",
      "\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "num_neurs = 0\n",
    "for key in results.keys():\n",
    "    print(key)\n",
    "    cache_idx_matrix = results[key]\n",
    "    sig_neurs = np.mean(cache_idx_matrix, axis=1)\n",
    "    threshold = 0.05\n",
    "    print(np.argwhere(sig_neurs > threshold).squeeze())\n",
    "    print()\n",
    "    num_neurs += np.sum(sig_neurs > threshold)\n",
    "print(num_neurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtractedWithXY_Cleaned184713_09102019.mat\n",
      "[0.         0.05079329 0.         0.         0.06526559 0.05651578\n",
      " 0.0398951  0.05690377 0.06913333 0.         0.         0.\n",
      " 0.         0.         0.07521125 0.06       0.         0.04825662\n",
      " 0.10237099 0.         0.         0.09576011 0.13013154 0.06666667\n",
      " 0.         0.0960751  0.05495119 0.06506667 0.         0.05651578\n",
      " 0.         0.         0.         0.         0.04937238 0.\n",
      " 0.         0.06666667 0.09772579 0.         0.         0.0430622 ]\n",
      "\n",
      "ExtractedWithXY_Cleaned184430_09102019.mat\n",
      "[0.         0.         0.04646714 0.         0.         0.\n",
      " 0.         0.0381932  0.13994673 0.0608229  0.05635063 0.\n",
      " 0.03918723 0.10737286 0.03039645 0.         0.         0.\n",
      " 0.         0.         0.00780379 0.         0.         0.11222594\n",
      " 0.24456872 0.08977544 0.         0.07692308 0.         0.04065934\n",
      " 0.07692308 0.03980322 0.         0.05837768 0.         0.\n",
      " 0.07692308 0.         0.         0.06753131 0.         0.\n",
      " 0.         0.         0.         0.         0.06395349 0.\n",
      " 0.         0.        ]\n",
      "\n",
      "ExtractedWithXY_Cleaned184526_09102019.mat\n",
      "[0.         0.         0.         0.07931727 0.11406879 0.06557923\n",
      " 0.         0.0466497  0.07463186 0.         0.         0.\n",
      " 0.         0.0376884  0.         0.19361661 0.         0.05480072\n",
      " 0.         0.         0.0706158  0.1345537  0.03487319 0.14301227\n",
      " 0.         0.         0.         0.         0.         0.18395944\n",
      " 0.         0.0378063  0.         0.         0.05661232 0.07638889\n",
      " 0.         0.         0.1370336  0.1417307  0.         0.\n",
      " 0.16963653 0.08333333 0.         0.         0.         0.        ]\n",
      "\n",
      "ExtractedWithXY_Cleaned184946_09102019.mat\n",
      "[0.         0.         0.         0.007      0.         0.\n",
      " 0.01331371 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06186\n",
      " 0.09497166 0.03850816 0.         0.04522727 0.03028169 0.\n",
      " 0.         0.         0.03984772 0.07544643 0.06962817 0.06973763\n",
      " 0.0252775  0.14257455 0.04084507 0.00925    0.         0.05\n",
      " 0.05058756 0.07904796 0.07497412 0.         0.04275    0.03955224\n",
      " 0.         0.         0.01366011 0.         0.18631432 0.05\n",
      " 0.08022727 0.09020577 0.11566715 0.03756219 0.03925    0.08656219\n",
      " 0.01218274 0.         0.05       0.05       0.         0.\n",
      " 0.         0.        ]\n",
      "\n",
      "ExtractedWithXY_Cleaned185033_09102019.mat\n",
      "[0.12678373 0.         0.00446571 0.         0.         0.02055733\n",
      " 0.         0.06337497 0.         0.0169059  0.05577245 0.10328855\n",
      " 0.02104377 0.         0.         0.         0.03044332 0.07936588\n",
      " 0.08477412 0.09090909 0.36363636 0.12599361 0.09090909 0.\n",
      " 0.06408855 0.         0.         0.07623925 0.05555556 0.24166113\n",
      " 0.         0.16524496 0.05727273 0.         0.         0.11954545\n",
      " 0.02966507 0.         0.04127161 0.09243016 0.07547699 0.04523773\n",
      " 0.08136364 0.03731762 0.08708134 0.         0.13916916 0.1314956\n",
      " 0.         0.1729798  0.06590909]\n",
      "\n",
      "ExtractedWithXY_Cleaned184331_09102019.mat\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.0075     0.         0.         0.03636364 0.         0.\n",
      " 0.         0.         0.195625   0.         0.         0.\n",
      " 0.05791667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02436548 0.         0.         0.\n",
      " 0.         0.         0.06881188 0.         0.07215909 0.\n",
      " 0.0893401  0.1        0.25276515 0.         0.09291667 0.\n",
      " 0.         0.17213902 0.         0.         0.        ]\n",
      "\n",
      "ExtractedWithXY_Cleaned144233_09112019.mat\n",
      "[0.         0.         0.01151651 0.         0.0295333  0.\n",
      " 0.         0.02405915 0.01114719 0.0962607  0.         0.00264982\n",
      " 0.         0.04765667 0.03478923 0.         0.         0.\n",
      " 0.04921278 0.05311769 0.03342845 0.         0.05275335 0.0382204\n",
      " 0.02211959 0.         0.         0.08978675 0.         0.04380909\n",
      " 0.16000927 0.04206663 0.07732008 0.07077846 0.06816134 0.\n",
      " 0.10176232 0.         0.         0.         0.003276   0.\n",
      " 0.         0.         0.06180912 0.13737299 0.05158313 0.\n",
      " 0.         0.04278075 0.         0.         0.         0.07225737\n",
      " 0.         0.        ]\n",
      "\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "num_neurs = 0\n",
    "for key in results.keys():\n",
    "    print(key)\n",
    "    cache_idx_matrix = results[key]\n",
    "    sig_neurs = np.mean(cache_idx_matrix, axis=1)\n",
    "    print(sig_neurs)\n",
    "    print()\n",
    "    num_neurs += np.sum(sig_neurs>0)\n",
    "print(num_neurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
